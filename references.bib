@misc{xie2021multispeaker,
      title={The Multi-speaker Multi-style Voice Cloning Challenge 2021}, 
      author={Qicong Xie and Xiaohai Tian and Guanghou Liu and Kun Song and Lei Xie and Zhiyong Wu and Hai Li and Song Shi and Haizhou Li and Fen Hong and Hui Bu and Xin Xu},
      year={2021},
      eprint={2104.01818},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@ARTICLE{8999436,
  author={Partila, Pavol and Tovarek, Jaromir and Ilk, Gokhan Hakki and Rozhon, Jan and Voznak, Miroslav},
  journal={IEEE Communications Magazine}, 
  title={Deep Learning Serves Voice Cloning: How Vulnerable Are Automatic Speaker Veriﬁcation Systems to Spooﬁng Trials?}, 
  year={2020},
  volume={58},
  number={2},
  pages={100-105},
  doi={10.1109/MCOM.001.1900396}}
  
@INPROCEEDINGS{9239750,
  author={Zhao, Li and Chen, Feifan},
  booktitle={2020 International Conference on Computer Network, Electronic and Automation (ICCNEA)}, 
  title={Research on Voice Cloning with a Few Samples}, 
  year={2020},
  volume={},
  number={},
  pages={323-328},
  doi={10.1109/ICCNEA50255.2020.00073}}
  
@ARTICLE{9312676,
  author={Hwang, Sung-Woong and Chang, Joon-Hyuk},
  journal={IEEE Access}, 
  title={Document-Level Neural TTS Using Curriculum Learning and Attention Masking}, 
  year={2021},
  volume={9},
  number={},
  pages={8954-8960},
  doi={10.1109/ACCESS.2020.3049073}}

@article{DBLP:journals/corr/abs-1810-06865,
  author    = {Jing{-}Xuan Zhang and
               Zhen{-}Hua Ling and
               Li{-}Juan Liu and
               Yuan Jiang and
               Li{-}Rong Dai},
  title     = {Sequence-to-Sequence Acoustic Modeling for Voice Conversion},
  journal   = {CoRR},
  volume    = {abs/1810.06865},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.06865},
  eprinttype = {arXiv},
  eprint    = {1810.06865},
  timestamp = {Tue, 20 Oct 2020 15:44:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-06865.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8639589,
  author={Mimura, Masato and Ueno, Sei and Inaguma, Hirofumi and Sakai, Shinsuke and Kawahara, Tatsuya},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Leveraging Sequence-to-Sequence Speech Synthesis for Enhancing Acoustic-to-Word Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={477-484},
  doi={10.1109/SLT.2018.8639589}}
  
@INPROCEEDINGS{8682816,
  author={Ueno, Sei and Mimura, Masato and Sakai, Shinsuke and Kawahara, Tatsuya},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multi-speaker Sequence-to-sequence Speech Synthesis for Data Augmentation in Acoustic-to-word Speech Recognition}, 
  year={2019},
  volume={},
  number={},
  pages={6161-6165},
  doi={10.1109/ICASSP.2019.8682816}}
  
@article{DBLP:journals/corr/abs-1712-05884,
  author    = {Jonathan Shen and
               Ruoming Pang and
               Ron J. Weiss and
               Mike Schuster and
               Navdeep Jaitly and
               Zongheng Yang and
               Zhifeng Chen and
               Yu Zhang and
               Yuxuan Wang and
               R. J. Skerry{-}Ryan and
               Rif A. Saurous and
               Yannis Agiomyrgiannakis and
               Yonghui Wu},
  title     = {Natural {TTS} Synthesis by Conditioning WaveNet on Mel Spectrogram
               Predictions},
  journal   = {CoRR},
  volume    = {abs/1712.05884},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.05884},
  eprinttype = {arXiv},
  eprint    = {1712.05884},
  timestamp = {Thu, 28 Nov 2019 08:59:52 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-05884.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
  
@INPROCEEDINGS{9289599,
  author={Win, Yuzana and Masada, Tomonari},
  booktitle={2020 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Myanmar Text-to-Speech System based on Tacotron-2}, 
  year={2020},
  volume={},
  number={},
  pages={578-583},
  doi={10.1109/ICTC49870.2020.9289599}}

@article{DBLP:journals/corr/abs-1806-04558,
  author    = {Ye Jia and
               Yu Zhang and
               Ron J. Weiss and
               Quan Wang and
               Jonathan Shen and
               Fei Ren and
               Zhifeng Chen and
               Patrick Nguyen and
               Ruoming Pang and
               Ignacio Lopez{-}Moreno and
               Yonghui Wu},
  title     = {Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech
               Synthesis},
  journal   = {CoRR},
  volume    = {abs/1806.04558},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.04558},
  eprinttype = {arXiv},
  eprint    = {1806.04558},
  timestamp = {Thu, 28 Nov 2019 08:59:49 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-04558.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hunt1996UnitSI,
  title={Unit selection in a concatenative speech synthesis system using a large speech database},
  author={Andrew J. Hunt and Alan W. Black},
  journal={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  year={1996},
  volume={1},
  pages={373-376 vol. 1}
}

@article{ZEN20091039,
title = {Statistical parametric speech synthesis},
journal = {Speech Communication},
volume = {51},
number = {11},
pages = {1039-1064},
year = {2009},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2009.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639309000648},
author = {Heiga Zen and Keiichi Tokuda and Alan W. Black},
keywords = {Speech synthesis, Unit selection, Hidden Markov models},
abstract = {This review gives a general overview of techniques used in statistical parametric speech synthesis. One instance of these techniques, called hidden Markov model (HMM)-based speech synthesis, has recently been demonstrated to be very effective in synthesizing acceptable speech. This review also contrasts these techniques with the more conventional technique of unit-selection synthesis that has dominated speech synthesis over the last decade. The advantages and drawbacks of statistical parametric synthesis are highlighted and we identify where we expect key developments to appear in the immediate future.}
}

@INPROCEEDINGS{6639215,
  author={Ze, Heiga and Senior, Andrew and Schuster, Mike},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Statistical parametric speech synthesis using deep neural networks}, 
  year={2013},
  volume={},
  number={},
  pages={7962-7966},
  doi={10.1109/ICASSP.2013.6639215}}
  
@inproceedings{wan2018generalized,
  title={Generalized end-to-end loss for speaker verification},
  author={Wan, Li and Wang, Quan and Papir, Alan and Moreno, Ignacio Lopez},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4879--4883},
  year={2018},
  organization={IEEE}
}

@article{DBLP:journals/corr/OordDZSVGKSK16,
  author    = {A{\"{a}}ron van den Oord and
               Sander Dieleman and
               Heiga Zen and
               Karen Simonyan and
               Oriol Vinyals and
               Alex Graves and
               Nal Kalchbrenner and
               Andrew W. Senior and
               Koray Kavukcuoglu},
  title     = {WaveNet: {A} Generative Model for Raw Audio},
  journal   = {CoRR},
  volume    = {abs/1609.03499},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.03499},
  eprinttype = {arXiv},
  eprint    = {1609.03499},
  timestamp = {Thu, 14 Oct 2021 09:15:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/OordDZSVGKSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bisani2008joint,
  title={Joint-sequence models for grapheme-to-phoneme conversion},
  author={Bisani, Maximilian and Ney, Hermann},
  journal={Speech communication},
  volume={50},
  number={5},
  pages={434--451},
  year={2008},
  publisher={Elsevier}
}

@article{2019,
   title={Transformer Based Grapheme-to-Phoneme Conversion},
   url={http://dx.doi.org/10.21437/Interspeech.2019-1954},
   DOI={10.21437/interspeech.2019-1954},
   journal={Interspeech 2019},
   publisher={ISCA},
   author={Yolchuyeva, Sevinj and Németh, Géza and Gyires-Tóth, Bálint},
   year={2019},
   month={Sep}
}

@article{DBLP:journals/corr/HeigoldMBS15,
  author    = {Georg Heigold and
               Ignacio Moreno and
               Samy Bengio and
               Noam Shazeer},
  title     = {End-to-End Text-Dependent Speaker Verification},
  journal   = {CoRR},
  volume    = {abs/1509.08062},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.08062},
  eprinttype = {arXiv},
  eprint    = {1509.08062},
  timestamp = {Mon, 13 Aug 2018 16:49:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeigoldMBS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{li2017deep,
  title={Deep speaker feature learning for text-independent speaker verification},
  author={Li, Lantian and Chen, Yixiang and Shi, Ying and Tang, Zhiyuan and Wang, Dong},
  journal={arXiv preprint arXiv:1705.03670},
  year={2017}
}

@article{DBLP:journals/corr/ArikDGMPPRZ17,
  author    = {Sercan {\"{O}}mer Arik and
               Gregory F. Diamos and
               Andrew Gibiansky and
               John Miller and
               Kainan Peng and
               Wei Ping and
               Jonathan Raiman and
               Yanqi Zhou},
  title     = {Deep Voice 2: Multi-Speaker Neural Text-to-Speech},
  journal   = {CoRR},
  volume    = {abs/1705.08947},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.08947},
  eprinttype = {arXiv},
  eprint    = {1705.08947},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ArikDGMPPRZ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{9414001,  author={Xie, Qicong and Tian, Xiaohai and Liu, Guanghou and Song, Kun and Xie, Lei and Wu, Zhiyong and Li, Hai and Shi, Song and Li, Haizhou and Hong, Fen and Bu, Hui and Xu, Xin},  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={The Multi-Speaker Multi-Style Voice Cloning Challenge 2021},   year={2021},  volume={},  number={},  pages={8613-8617},  doi={10.1109/ICASSP39728.2021.9414001}}

@misc{weko_4379_1,
   author	 = "Prof. Koichi Shinoda and Prof. Sadaoki Furui (Tokyo Institute of Technology)",
   title	 = "Tokyo Institute of Technology Multilingual Speech Corpus - Indonesian (TITML-IDN)",
   month	 = "nov",
   year 	 = "2011"
}
